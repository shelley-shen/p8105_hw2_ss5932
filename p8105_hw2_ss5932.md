Homework 2
================
Shelley Shen
09/26/2020

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------------------------------------------------------------------------------- tidyverse 1.3.0 --

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts ------------------------------------------------------------------------------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dplyr)
library(readr)
```

## Problem 1: Mr. Trash Wheel

Read and clean the Mr. Trash Wheel sheet.

``` r
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",   
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean precipitation data for 2018 and 2017.

``` r
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2018 Precipitation", 
    skip = 1, 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018,
         total = as.numeric(total)) %>%
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2017 Precipitation", 
    skip = 1, 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation and change month number to name by
creating separate month tibble.

``` r
month_df = 
  tibble(
    month = 1:12, 
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # ... with 14 more rows

This dataset contains information from the Mr. Trash Wheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trash wheel collects that trash and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, including some
specific kinds of trash. There are a total of 14 columns and 344 rows in
our final dataset. Additional data sheets include month and
precipitation data for each year between 2014-2019.

  - The total precipitation in 2018 was 70.33 inches.

  - The median number of sports balls in a dumpster in 2017 was 8 balls.

## Problem 2: NYC Transit

**Part 1: Read and clean the NYC Transit data.**

After importing the data, I will clean the names by making all text
lowercase and in snake case. Then I will select the variables of
interest and convert the entry variable into a logical vector.

``` r
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE")) 
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The data is not tidy yet as each route is a distinct variable and needs
to be further cleaned by converting the route variables into the same
type of vector and then using pivot\_longer to merge the routes into one
variable.

``` r
nyc_transit_tidy = 
  nyc_transit_df %>% 
    mutate(
      route8 = as.character(route8), 
      route9 = as.character(route9),
      route10 = as.character(route10), 
      route11 = as.character(route11))

nyc_transit_tidy = 
  pivot_longer(
    nyc_transit_tidy, 
    route1:route11, 
    names_to = "route_name", 
    names_prefix = "route",
    values_to = "route_number")

view(nyc_transit_tidy)
```

The NYC Transit dataset contains a variety of variables pertaining to
the NYC transit system. After reading in the csv file, I cleaned the
data by first cleaning the names to make all variable names in the same
format with lowercase letters and snake case. Then, I used the select
command to retain only the variables of interest and omit all other
extraneous variables. The following variables are those of interest:
line, station, name, station latitude and longitude, routes served,
entry, entrance type, vending, and ADA compliance. Next, I converted the
“entry” variable from the original character vector into a logical
vector by using the recode function embedded in the mutate function. In
an effort to make the data more tidy, I converted all the route
variables into character vectors so they can be merged via pivot\_longer
and all the routes are under only two columns.

The resulting dataset contains a total of 20548 observations with 20548
rows and 10 columns. The variables in the dataset are line,
station\_name, station\_latitude, station\_longitude, entrance\_type,
entry, vending, ada, route\_name, route\_number. The data is quite tidy
now.

**Part 2: Details about the NYC Transit data.**

Find the number of distant stations, the number of ADA compliant
stations, and the proportion of station entrances and exits without
vending that allow entrance.

  - There are 465 distinct stations in the NYC transit system.

  - There are 84 distinct stations that are ADA compliant.

  - The proportion of station entrances/exits without vending that allow
    entrance is 0.3770492.

  - There are 60 distinct stations that serve the A train.

  - Of the distinct stations that serve the A train, 17 are ADA
    compliant.

## Problem 3: FiveThirtyEight

**Part 1: pols data**

Read and clean data in pols-month csv file. I will first separate the
date variable into year, month, and day and then remove the day
variable. Then I will create a president variable and remove the
variables used to create it. I will also convert year and month into
factor variables to ensure that it can merge with the other datasets
later.

``` r
pols_df = 
  read_csv("./data/538_data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    month = as.factor(month.abb[as.factor(month)]),
    year = as.factor(year),
    president = case_when( 
     prez_gop == 1 ~ "gop",
     prez_dem == 1 ~ "dem",
     prez_gop == 2 ~ "gop"
    )) %>% 
  subset(select = -c(day, prez_gop, prez_dem))
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

The prez\_gop variable in the pols dataset indicated whether the
president was Republican on the associated date, with 1 = yes and 0 =
no. During the year 1974, the value was actually 2, indicating that
something else was occurring. The data source does not explain what this
unexpected value means. But when reviewing the history of US presidents,
we remember that Richard Nixon served as president from 1969 until 1974.
In 1974, he was impeached for the Watergate scandal and those dates
coincide with the dates when the prez\_gop variable has a value of 2.

**Part 2: snp data**

Read and clean data in snp csv file using the same process as above. I
will first separate the date variable into separate year, month, and day
columns, then remove the day variable. I will also convert year and
month into factor variables to ensure that it can merge with the other
datasets later.

``` r
snp_df = 
  read_csv("./data/538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year")) %>%
  mutate(
    month = as.factor(month.abb[as.factor(month)]),
    year = as.factor(year),
    close = as.factor(close)) %>% 
    relocate(year, month) %>% 
  subset(select = -c(day))
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

**Part 3: unemployment data**

Read and clean data in unemployment csv file using similar process as
above and use pivot\_longer to merge the month variables into one
columnn with their respective values into a separate percentage
unemployed column. I will also convert year and month into factor
variables to ensure that it can merge with the other datasets later, and
capitalize the month names so they align with the months in the other
datasets.

``` r
unemploy_df = 
  read_csv("./data/538_data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  rename(Jan = jan, Feb = feb, Mar = mar, Apr = apr, May = may, Jun = jun, Jul = jul, Aug = aug, Sep = sep, Oct = oct, Nov = nov, Dec = dec) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "percent_unemployed") %>% 
  mutate(
    year = as.factor(year),
    month = as.factor(month),
    percent_unemployed = as.factor(percent_unemployed))
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

**Part 4: merge all datasets**

``` r
pols_snp = 
  left_join(
    pols_df, snp_df, by = c("year", "month"))


final_df = 
  left_join(
    pols_snp, unemploy_df, by = c("year", "month"))

View(final_df)
```

**Description of datasets:**

The data in the pols, snp, and unemployment datasets come from the
FiveThirtyEight website founded by Nate Silver, who is a statistician
that analyzes politics, economics, and sports. He created an interactive
statistical graphic showing the association between political party and
economic success in the United States based on various inputs relating
to government and politics. The data in these datasets underlie this
interactive graphic.

The pols dataset contains information regarding the number of national
politicians who identified as Republican or Democratic at any given time
between the years 1947 - 2015. There are a total of 822 observations in
the pols dataset.

The snp dataset contains information regarding the Standard & Poor’s
stock market index (S\&P) and the closing values of the S\&P on the
associated date. NA values arise in this dataset on dates prior to 1950,
indicating that no measurements were obtained or available on the S\&P’s
closing values prior to January 1950. There are a total of 787
observations in the snp dataset which range from 1950 until 2015.

The unemployment dataset contains information regarding the percentage
of unemployment on the associated date. NA values arise in this dataset
on dates prior to 1948, indicating that no measurements were obtained or
available on unemployment until January 1948. There are a total of 816
observations in the unemployment dataset which range from 1948 until
2015.

The final dataset merged the individual pols, snp, and unemployment data
and has 822 monthly observations and ’r ncol(final\_df)\` variables. The
important variables include the president’s political affiliation,
unemployment rate, and closing value for the S\&P stock index from 1947
to 2015.
