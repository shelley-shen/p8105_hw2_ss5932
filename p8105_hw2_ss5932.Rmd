---
title: "Homework 2"
author: Shelley Shen
date: 09/26/2020
output: github_document
---
```{r setup}
library(tidyverse)
library(readxl)
library(dplyr)
library(readr)
```

## Problem 1: Mr. Trash Wheel

Read and clean the Mr. Trash Wheel sheet. I will import the data from the Mr. Trash Wheel Excel sheet, format variable names with snake case, remove non-data values, including the rows and columns with annotations and values that do not pertain to the dumpster data. 

```{r Mr_Trash_Wheel}
trashwheel_df = 
  read_xlsx("./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",   
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read and clean precipitation data for 2018 and 2017. I will import the data from the Excel sheets associated with the years of interest, remove rows without data, and create a new variable for year. 

```{r}
precip_2018 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2018 Precipitation", 
    skip = 1, 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018,
         total = as.numeric(total)) %>%
  relocate(year)

precip_2017 = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx", 
    sheet = "2017 Precipitation", 
    skip = 1, 
  ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>%
  relocate(year)
```


Now combine annual precipitation and change month number to name by creating a separate month tibble and then merging with left_join.  

```{r}
month_df = 
  tibble(
    month = 1:12, 
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")

```

This dataset contains information from the Mr. Trash Wheel trash collector in Baltimore, Maryland. As trash enters the inner harbor, the trash wheel collects that trash and stores it in a dumpster. The dataset contains information on year, month, and trash collected, including some specific kinds of trash. There are a total of `r ncol(trashwheel_df)` columns and `r nrow(trashwheel_df)` rows in our final dataset. Additional data sheets include month and precipitation data for each year between 2014-2019. 

- The total precipitation in 2018 was `r sum(pull(precip_2018, total))` inches. 

- The median number of sports balls in a dumpster in 2017 was `r median(pull(filter(trashwheel_df, year == 2017), sports_balls))` balls.




## Problem 2: NYC Transit

**Part 1: Read and clean the NYC Transit data.**

After importing the data, I will clean the names by making all text lowercase and in snake case. Then I will select the variables of interest and convert the entry variable into a logical vector. 

```{r NYC_Transit}
nyc_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:entry, vending, ada) %>%
  mutate(entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE")) 
```

The data is not tidy yet as each route is a distinct variable and needs to be further cleaned by converting the route variables into the same type of vector and then using pivot_longer to merge the routes into one variable. 

```{r}
nyc_transit_tidy = 
  nyc_transit_df %>% 
    mutate(
      route8 = as.character(route8), 
      route9 = as.character(route9),
      route10 = as.character(route10), 
      route11 = as.character(route11))

nyc_transit_tidy = 
  pivot_longer(
    nyc_transit_tidy, 
    route1:route11, 
    names_to = "route_name", 
    names_prefix = "route",
    values_to = "route_number")

view(nyc_transit_tidy)
```

The NYC Transit dataset contains a variety of variables pertaining to the NYC transit system. After reading in the csv file, I cleaned the data by first cleaning the names to make all variable names in the same format with lowercase letters and snake case. Then, I used the select command to retain only the variables of interest and omit all other extraneous variables. The following variables are those of interest: line, station, name, station latitude and longitude, routes served, entry, entrance type, vending, and ADA compliance. Next, I converted the "entry" variable from the original character vector into a logical vector by using the recode function embedded in the mutate function. In an effort to make the data more tidy, I converted all the route variables into character vectors so they can be merged via pivot_longer and all the routes are under only two columns. 

The resulting dataset contains a total of `r nrow(nyc_transit_tidy)` observations with `r nrow(nyc_transit_tidy)` rows and `r ncol(nyc_transit_tidy)` columns. The variables in the dataset are `r names(nyc_transit_tidy)`.  The data is quite tidy now. 



**Part 2: Details about the NYC Transit data.**

Find the number of distant stations, the number of ADA compliant stations, and the proportion of station entrances and exits without vending that allow entrance. 

- There are `r distinct(nyc_transit_tidy, line, station_name) %>% count()` distinct stations in the NYC transit system. 

- There are `r filter(nyc_transit_tidy, ada == "TRUE") %>% distinct(line, station_name) %>% count()` distinct stations that are ADA compliant. 

- The proportion of station entrances/exits without vending that allow entrance is `r filter(nyc_transit_tidy, entry == "TRUE", vending == "NO") %>% count()/filter(nyc_transit_tidy, vending == "NO") %>% count()`. 

- There are `r filter(nyc_transit_tidy, route_number == "A") %>% distinct(line, station_name) %>% count()` distinct stations that serve the A train. 

- Of the distinct stations that serve the A train, `r filter(nyc_transit_tidy, route_number == "A") %>% filter(ada == "TRUE") %>% distinct(line, station_name) %>% count()` are ADA compliant. 



## Problem 3: FiveThirtyEight

**Part 1: pols data**

Read and clean data in pols-month csv file. I will first separate the date variable into year, month, and day and then remove the day variable. Then I will create a president variable and remove the variables used to create it. I will also convert year and month into factor variables to ensure that it can merge with the other datasets later.

```{r pols}
pols_df = 
  read_csv("./data/538_data/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year", "month", "day")) %>% 
  mutate(
    month = as.factor(month.abb[as.factor(month)]),
    year = as.factor(year),
    president = case_when( 
     prez_gop == 1 ~ "gop",
     prez_dem == 1 ~ "dem",
     prez_gop == 2 ~ "gop"
    )) %>% 
  subset(select = -c(day, prez_gop, prez_dem))
```

The prez_gop variable in the pols dataset indicated whether the president was Republican on the associated date, with 1 = yes and 0 = no. During the year 1974, the value was actually 2, indicating that something else was occurring. The data source does not explain what this unexpected value means. But when reviewing the history of US presidents, we remember that Richard Nixon served as president from 1969 until 1974. In 1974, he was impeached for the Watergate scandal and those dates coincide with the dates when the prez_gop variable has a value of 2. 


**Part 2: snp data**

Read and clean data in snp csv file using the same process as above. I will first separate the date variable into separate year, month, and day columns, then remove the day variable. I will also convert year and month into factor variables to ensure that it can merge with the other datasets later. 

```{r snp}
snp_df = 
  read_csv("./data/538_data/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, c("month", "day", "year")) %>%
  mutate(
    month = as.factor(month.abb[as.factor(month)]),
    year = as.factor(year),
    close = as.factor(close)) %>% 
    relocate(year, month) %>% 
  subset(select = -c(day))
```

**Part 3: unemployment data**

Read and clean data in unemployment csv file using similar process as above and use pivot_longer to merge the month variables into one columnn with their respective values into a separate percentage unemployed column. I will also convert year and month into factor variables to ensure that it can merge with the other datasets later, and capitalize the month names so they align with the months in the other datasets. 

```{r unemploy}
unemploy_df = 
  read_csv("./data/538_data/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  rename(Jan = jan, Feb = feb, Mar = mar, Apr = apr, May = may, Jun = jun, Jul = jul, Aug = aug, Sep = sep, Oct = oct, Nov = nov, Dec = dec) %>% 
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "percent_unemployed") %>% 
  mutate(
    year = as.factor(year),
    month = as.factor(month),
    percent_unemployed = as.factor(percent_unemployed))
 
```

**Part 4: merge all datasets**

```{r final merges}
pols_snp = 
  left_join(
    pols_df, snp_df, by = c("year", "month"))


final_df = 
  left_join(
    pols_snp, unemploy_df, by = c("year", "month"))

View(final_df)
```

**Description of datasets:**

The data in the pols, snp, and unemployment datasets come from the FiveThirtyEight website founded by Nate Silver, who is a statistician that analyzes politics, economics, and sports. He created an interactive statistical graphic showing the association between political party and economic success in the United States based on various inputs relating to government and politics. The data in these datasets underlie this interactive graphic. 

The pols dataset contains information regarding the number of national politicians who identified as Republican or Democratic at any given time between the years 1947 - 2015. There are a total of `r nrow(pols_df)` observations in the pols dataset. 

The snp dataset contains information regarding the Standard & Poor's stock market index (S&P) and the closing values of the S&P on the associated date. NA values arise in this dataset on dates prior to 1950, indicating that no measurements were obtained or available on the S&P's closing values prior to January 1950. There are a total of `r nrow(snp_df)` observations in the snp dataset which range from 1950 until 2015. 

The unemployment dataset contains information regarding the percentage of unemployment on the associated date. NA values arise in this dataset on dates prior to 1948, indicating that no measurements were obtained or available on unemployment until January 1948. There are a total of `r nrow(unemploy_df)` observations in the unemployment dataset which range from 1948 until 2015. 

The final dataset merged the individual pols, snp, and unemployment data and has `r nrow(final_df)` monthly observations and 'r ncol(final_df)` variables. The important variables include the president's political affiliation, unemployment rate, and closing value for the S&P stock index from 1947 to 2015. 